"""ãƒ‡ãƒ¢A: æ±ç”¨æ–‡æ›¸æ§‹é€ åŒ–ã‚¨ãƒ³ã‚¸ãƒ³ â€” Streamlit UI"""

import sys
import json
import logging
import tempfile
import traceback
from pathlib import Path

# Streamlit Cloud ã§ã¯ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãŒ sys.path ã«å«ã¾ã‚Œãªã„ãŸã‚æ˜ç¤ºçš„ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# Streamlit Cloud ã®ãƒ­ã‚°ã« WARNING ä»¥ä¸Šã‚’å‡ºåŠ›ã™ã‚‹
logging.basicConfig(level=logging.WARNING, format="%(name)s %(levelname)s: %(message)s")

import streamlit as st

from app.demo_a.converter import TextContent, ensure_pdf
from app.demo_a.pipeline import build_index, extract_with_schema
from app.demo_a.presets import get_preset, list_presets

# --- ãƒ—ãƒªã‚»ãƒƒãƒˆæ–‡æ›¸å®šç¾© ---
RESOURCES_BASE = Path(__file__).parent.parent.parent / "resources" / "PoCè¦‹ç©ä¾é ¼_å®Ÿéš›ã®æ¥­å‹™è³‡æ–™"

PRESET_DOCUMENTS = {
    "Instructions to Bidders (Word)": RESOURCES_BASE / "å—æ³¨å‰" / "ãƒ†ãƒ³ãƒ€ãƒ¼æ›¸é¡" / "Instructions to Bidders_OCTG.docx",
    "Project Overview (Word)": RESOURCES_BASE / "å—æ³¨å‰" / "ãƒ†ãƒ³ãƒ€ãƒ¼æ›¸é¡" / "Project Overview_Mozambique.docx",
    "Exhibit D (Word)": RESOURCES_BASE / "å—æ³¨å‰" / "ãƒ†ãƒ³ãƒ€ãƒ¼æ›¸é¡" / "4.1-Exhibit D Comp and Paym_OCTG_All.docx",
    "Exhibit D - Large OD (Excel)": (
        RESOURCES_BASE / "å—æ³¨å‰" / "ãƒ†ãƒ³ãƒ€ãƒ¼æ›¸é¡" / "Large OD" / "Att 1-Exhibit D - OCTG Large OD.xlsx"
    ),
    "Exhibit D - Chrome (Excel)": (
        RESOURCES_BASE / "å—æ³¨å‰" / "ãƒ†ãƒ³ãƒ€ãƒ¼æ›¸é¡" / "Chrome" / "Att 1-Exhibit D - OCTG Cr.xlsx"
    ),
    "Base Contract (PDF, 230p)": (
        RESOURCES_BASE / "å—æ³¨å¾Œ" / "Input from customer & mill" / "PO" / "Base Contract_00008772-CTR109083 TEPRH AGUP Ph2 OCTG CRA CONTRACT Signed.pdf"
    ),
    "CallOff PO (PDF)": (
        RESOURCES_BASE / "å—æ³¨å¾Œ" / "Input from customer & mill" / "PO" / "CallOff 4300062653 - AGUP P2 - Sumitomo (FINAL).pdf"
    ),
}

# --- ãƒ­ã‚®ãƒ³ã‚°è¨­å®š ---
# Streamlitã®UIã«ãƒ­ã‚°ã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒãƒ³ãƒ‰ãƒ©
class StreamlitLogHandler(logging.Handler):
    """ãƒ­ã‚°ã‚’st.session_stateã«è“„ç©ã™ã‚‹ãƒãƒ³ãƒ‰ãƒ©ã€‚"""

    def emit(self, record: logging.LogRecord) -> None:
        if "log_messages" not in st.session_state:
            st.session_state.log_messages = []
        msg = self.format(record)
        st.session_state.log_messages.append(msg)


# appé…ä¸‹ã®ãƒ­ã‚¬ãƒ¼ã«ãƒãƒ³ãƒ‰ãƒ©ã‚’è¨­å®š
_log_handler = StreamlitLogHandler()
_log_handler.setFormatter(logging.Formatter("%(asctime)s [%(levelname)s] %(name)s: %(message)s", datefmt="%H:%M:%S"))
_app_logger = logging.getLogger("app")
_app_logger.setLevel(logging.DEBUG)
if not any(isinstance(h, StreamlitLogHandler) for h in _app_logger.handlers):
    _app_logger.addHandler(_log_handler)

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="ãƒ‡ãƒ¢A: æ±ç”¨æ–‡æ›¸æ§‹é€ åŒ–ã‚¨ãƒ³ã‚¸ãƒ³", page_icon="ğŸ“„", layout="wide")
st.title("åŸºç›¤â‘  æ–‡æ›¸å‡¦ç†ãƒ»æ§‹é€ åŒ–ç”Ÿæˆ ãƒ‡ãƒ¢")

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ– ---
for key, default in {
    "index_cache": None,  # (pdf_path, batches, chunk_index)
    "extraction_results": None,
    "current_file_id": None,  # ãƒ•ã‚¡ã‚¤ãƒ«è­˜åˆ¥ã‚­ãƒ¼
    "current_schema_key": None,  # ã‚¹ã‚­ãƒ¼ãƒè­˜åˆ¥ã‚­ãƒ¼
    "uploaded_temp_path": None,  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€æ™‚ä¿å­˜ãƒ‘ã‚¹
    "uploaded_file_id": None,  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã®è­˜åˆ¥ã‚­ãƒ¼ï¼ˆtempå†ä½œæˆåˆ¤å®šç”¨ï¼‰
    "log_messages": [],  # å®Ÿè¡Œãƒ­ã‚°
}.items():
    if key not in st.session_state:
        st.session_state[key] = default


def _make_schema_key(fields: list[dict]) -> str:
    """ã‚¹ã‚­ãƒ¼ãƒã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ã‹ã‚‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚­ãƒ¼ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    parts = tuple((f.get("name", ""), f.get("type", ""), f.get("description", "")) for f in fields)
    return str(parts)


# ===== ã‚µã‚¤ãƒ‰ãƒãƒ¼ =====
with st.sidebar:
    st.header("ğŸ“„ æ–‡æ›¸é¸æŠ")
    doc_source = st.radio("å…¥åŠ›æ–¹æ³•", ["ãƒ—ãƒªã‚»ãƒƒãƒˆæ–‡æ›¸", "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"], horizontal=True)

    selected_file_path: Path | None = None
    file_id: str | None = None

    if doc_source == "ãƒ—ãƒªã‚»ãƒƒãƒˆæ–‡æ›¸":
        available_docs = {name: path for name, path in PRESET_DOCUMENTS.items() if path.exists()}
        if not available_docs:
            st.warning("ãƒ—ãƒªã‚»ãƒƒãƒˆæ–‡æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚resources/ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            selected_doc_name = st.selectbox("æ–‡æ›¸ã‚’é¸æŠ", list(available_docs.keys()))
            selected_file_path = available_docs[selected_doc_name]
            file_id = f"preset:{selected_file_path}"
            st.caption(f"å½¢å¼: {selected_file_path.suffix.upper()}")
    else:
        uploaded_file = st.file_uploader(
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=["pdf", "docx", "xlsx", "xlsm", "pptx", "csv", "txt"],
        )
        if uploaded_file:
            file_id = f"upload:{uploaded_file.name}:{uploaded_file.size}"
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰ã‚ã£ãŸå ´åˆã®ã¿ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆrerunã”ã¨ã®ãƒªãƒ¼ã‚¯ã‚’é˜²æ­¢ï¼‰
            if st.session_state.uploaded_file_id != file_id:
                suffix = Path(uploaded_file.name).suffix
                tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
                tmp.write(uploaded_file.getvalue())
                tmp.close()
                st.session_state.uploaded_temp_path = tmp.name
                st.session_state.uploaded_file_id = file_id
            selected_file_path = Path(st.session_state.uploaded_temp_path)
            st.caption(f"å½¢å¼: {Path(uploaded_file.name).suffix.upper()} / ã‚µã‚¤ã‚º: {uploaded_file.size / 1024:.0f} KB")

    st.divider()
    st.header("ğŸ“‹ ã‚¹ã‚­ãƒ¼ãƒé¸æŠ")
    schema_mode = st.radio("å®šç¾©æ–¹æ³•", ["ãƒ—ãƒªã‚»ãƒƒãƒˆ", "ã‚«ã‚¹ã‚¿ãƒ å®šç¾©"], horizontal=True)

    field_definitions: list[dict] = []

    if schema_mode == "ãƒ—ãƒªã‚»ãƒƒãƒˆ":
        presets = list_presets()
        preset_names = [p["name"] for p in presets]
        selected_preset_name = st.selectbox("ãƒ—ãƒªã‚»ãƒƒãƒˆã‚’é¸æŠ", preset_names)
        preset = get_preset(selected_preset_name)
        field_definitions = preset["fields"]
        st.caption(f"{len(field_definitions)} é …ç›®")

        with st.expander("ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¸€è¦§"):
            for f in field_definitions:
                st.text(f"  {f['name']} ({f['type']}): {f['description']}")
    else:
        st.caption("æŠ½å‡ºã—ãŸã„é …ç›®ã‚’å®šç¾©ã—ã¦ãã ã•ã„")
        num_fields = st.number_input("ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°", min_value=1, max_value=20, value=3)
        for i in range(int(num_fields)):
            cols = st.columns([2, 1, 3])
            name = cols[0].text_input(f"åå‰ #{i + 1}", key=f"fname_{i}", value=f"field_{i + 1}")
            ftype = cols[1].selectbox(f"å‹ #{i + 1}", ["ãƒ†ã‚­ã‚¹ãƒˆ", "æ•°å€¤", "æ•´æ•°", "çœŸå½"], key=f"ftype_{i}")
            desc = cols[2].text_input(f"èª¬æ˜ #{i + 1}", key=f"fdesc_{i}", value="")
            if name and desc:
                field_definitions.append({"name": name, "type": ftype, "description": desc})

    # --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ– ---
    schema_key = _make_schema_key(field_definitions)

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¤‰ã‚ã£ãŸã‚‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨æŠ½å‡ºçµæœã‚’ã‚¯ãƒªã‚¢
    if file_id != st.session_state.current_file_id:
        st.session_state.index_cache = None
        st.session_state.extraction_results = None
        st.session_state.current_file_id = file_id

    # ã‚¹ã‚­ãƒ¼ãƒãŒå¤‰ã‚ã£ãŸã‚‰æŠ½å‡ºçµæœã‚’ã‚¯ãƒªã‚¢ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¯å†åˆ©ç”¨å¯ï¼‰
    if schema_key != st.session_state.current_schema_key:
        st.session_state.extraction_results = None
        st.session_state.current_schema_key = schema_key

    # æ–‡æ›¸æƒ…å ±
    if st.session_state.index_cache:
        st.divider()
        st.header("ğŸ“Š æ–‡æ›¸æƒ…å ±")
        _, batches, chunk_index = st.session_state.index_cache
        if len(batches) == 1:
            st.metric("ãƒšãƒ¼ã‚¸æ•°", batches[0]["page_count"])
            st.caption("å‡¦ç†æ–¹å¼: ç›´æ¥æŠ•å…¥ï¼ˆ100pä»¥ä¸‹ï¼‰")
        else:
            total_pages = batches[-1]["page_end"]
            st.metric("ãƒšãƒ¼ã‚¸æ•°", total_pages)
            st.metric("ãƒãƒƒãƒæ•°", len(batches))
            if chunk_index:
                st.metric("ãƒãƒ£ãƒ³ã‚¯æ•°", len(chunk_index))
            st.caption("å‡¦ç†æ–¹å¼: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚¯")

    # å®Ÿè¡Œãƒ­ã‚°ï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ä¸‹éƒ¨ã«å¸¸æ™‚è¡¨ç¤ºï¼‰
    if st.session_state.log_messages:
        st.divider()
        st.header("ğŸ“ å®Ÿè¡Œãƒ­ã‚°")
        log_text = "\n".join(st.session_state.log_messages)
        st.code(log_text, language="text")
        if st.button("ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.log_messages = []
            st.rerun()


# ===== ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ =====

if selected_file_path and field_definitions:
    # --- ãƒ•ã‚§ãƒ¼ã‚º1: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ ---
    if st.session_state.index_cache is None:
        st.subheader("ãƒ•ã‚§ãƒ¼ã‚º1: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰")

        with st.status("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ä¸­...", expanded=True) as status:
            # Step 1: PDFå¤‰æ›
            st.write("Step 1: ãƒ•ã‚¡ã‚¤ãƒ«å—ä»˜ â†’ PDFåŒ–")
            try:
                pdf_result = ensure_pdf(selected_file_path, output_dir=Path("output/converted"))
            except Exception as e:
                st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                with st.expander("ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ï¼ˆè©³ç´°ï¼‰", expanded=True):
                    st.code(traceback.format_exc(), language="python")
                st.stop()

            if isinstance(pdf_result, TextContent):
                st.warning(
                    "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¯ç¾åœ¨PDFãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚PDF/Word/Excelã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
                )
                st.stop()

            st.write(f"  â†’ PDFå¤‰æ›å®Œäº†: {pdf_result.name}")

            # Step 2-3: ãƒãƒƒãƒåˆ†å‰² + ãƒãƒ£ãƒ³ã‚¯ç”Ÿæˆ
            st.write("Step 2-3: ãƒãƒƒãƒåˆ†å‰² + ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰")
            try:
                pdf_path, batches, chunk_index = build_index(pdf_result)
            except Exception as e:
                st.error(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰ã‚¨ãƒ©ãƒ¼: {e}")
                with st.expander("ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ï¼ˆè©³ç´°ï¼‰", expanded=True):
                    st.code(traceback.format_exc(), language="python")
                st.stop()

            if len(batches) == 1:
                st.write(f"  â†’ {batches[0]['page_count']}ãƒšãƒ¼ã‚¸ï¼ˆåˆ†å‰²ä¸è¦ï¼‰")
            else:
                st.write(f"  â†’ {len(batches)}ãƒãƒƒãƒã«åˆ†å‰²")
                if chunk_index:
                    st.write(f"  â†’ {len(chunk_index)}å€‹ã®ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãƒãƒ£ãƒ³ã‚¯ã‚’ç”Ÿæˆ")

            st.session_state.index_cache = (pdf_path, batches, chunk_index)
            status.update(label="ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰å®Œäº†", state="complete", expanded=False)
    else:
        st.subheader("ãƒ•ã‚§ãƒ¼ã‚º1: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰")
        st.success("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ§‹ç¯‰æ¸ˆã¿ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ï¼‰")

    # --- ãƒ•ã‚§ãƒ¼ã‚º2: æ¤œç´¢â†’æŠ½å‡º ---
    st.subheader("ãƒ•ã‚§ãƒ¼ã‚º2: æ¤œç´¢ â†’ æŠ½å‡º")

    col1, col2 = st.columns([1, 4])
    run_extraction = col1.button("â–¶ æŠ½å‡ºå®Ÿè¡Œ", type="primary", use_container_width=True)

    if run_extraction:
        pdf_path, batches, chunk_index = st.session_state.index_cache
        # ãƒ­ã‚°ã‚’ã‚¯ãƒªã‚¢
        st.session_state.log_messages = []

        with st.status("æŠ½å‡ºä¸­...", expanded=True) as status:
            if chunk_index:
                st.write("Step 5: ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°")
                st.write("Step 6: ãƒãƒ£ãƒ³ã‚¯æ¤œç´¢")
                st.write("Step 7: ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆçµ±åˆ")
            st.write("Step 8: æ§‹é€ åŒ–æŠ½å‡ºï¼ˆSonnet 4.6ï¼‰")
            st.write(f"  ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ•°: {len(field_definitions)}")
            st.write(f"  ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: {', '.join(f['name'] for f in field_definitions)}")

            try:
                results = extract_with_schema(pdf_path, batches, chunk_index, field_definitions)
            except Exception as e:
                status.update(label="æŠ½å‡ºå¤±æ•—", state="error", expanded=True)
                st.error(f"æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")

                # ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯è¡¨ç¤º
                tb = traceback.format_exc()
                with st.expander("ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ï¼ˆè©³ç´°ï¼‰", expanded=True):
                    st.code(tb, language="python")

                # ã‚¹ã‚­ãƒ¼ãƒæƒ…å ±è¡¨ç¤º
                from app.demo_a.schema_builder import build_extraction_schema

                try:
                    debug_model = build_extraction_schema(field_definitions)
                    schema_json = debug_model.model_json_schema()
                    with st.expander("é€ä¿¡ã‚¹ã‚­ãƒ¼ãƒï¼ˆJSON Schemaï¼‰", expanded=True):
                        st.json(schema_json)
                except Exception:
                    pass

                st.info("è©³ç´°ãƒ­ã‚°ã¯ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œå®Ÿè¡Œãƒ­ã‚°ã€ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

                st.stop()

            st.session_state.extraction_results = results
            status.update(label="æŠ½å‡ºå®Œäº†", state="complete", expanded=False)

    # --- çµæœè¡¨ç¤º ---
    if st.session_state.extraction_results:
        results = st.session_state.extraction_results

        st.subheader("æŠ½å‡ºçµæœ")

        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        table_data = []
        for r in results:
            status_icon = "âœ…" if r["found_in_document"] else "âŒ"
            table_data.append(
                {
                    "çŠ¶æ…‹": status_icon,
                    "é …ç›®": r["field_name"],
                    "èª¬æ˜": r["description"],
                    "æŠ½å‡ºå€¤": str(r["value"]) if r["value"] is not None else "â€”",
                    "ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹": r["status"],
                }
            )

        st.dataframe(table_data, use_container_width=True, hide_index=True)

        # çµ±è¨ˆ
        found = sum(1 for r in results if r["found_in_document"])
        total = len(results)
        st.metric("æŠ½å‡ºç‡", f"{found}/{total} ({found / total * 100:.0f}%)")

        # JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        json_data = {r["field_name"]: r["value"] for r in results}
        st.download_button(
            "ğŸ“¥ JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=json.dumps(json_data, ensure_ascii=False, indent=2),
            file_name="extraction_result.json",
            mime="application/json",
        )

        # è©³ç´°JSONï¼ˆå±•é–‹å¯èƒ½ï¼‰
        with st.expander("ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆJSONï¼‰"):
            st.json(results)

elif not selected_file_path:
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰æ–‡æ›¸ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")
elif not field_definitions:
    st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã‚¹ã‚­ãƒ¼ãƒã‚’å®šç¾©ã—ã¦ãã ã•ã„ã€‚")
